{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730877001.835906   43098 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730877001.864580   43098 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730877001.864740   43098 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "gpu_memory_limit = 2048  # in MB\n",
    "\n",
    "# Configure GPU memory limit\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Set the memory limit for each GPU\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=gpu_memory_limit)]\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#!pip install tensorflow-datasets\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Embedding, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
    "##!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
    "\n",
    "train_file_path = \"train-data.tsv\"\n",
    "test_file_path = \"valid-data.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>ahhhh...just woken up!had a bad dream about u ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>you can never do nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>now u sound like manky scouse boy steve,like! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>mum say we wan to go then go... then she can s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>never y lei... i v lazy... got wat? dat day ü ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>ham</td>\n",
       "      <td>just woke up. yeesh its late. but i didn't fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>ham</td>\n",
       "      <td>what do u reckon as need 2 arrange transport i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry into our £250 weekly competition ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>spam</td>\n",
       "      <td>-pls stop bootydelious (32/f) is inviting you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4178</th>\n",
       "      <td>ham</td>\n",
       "      <td>tell my  bad character which u dnt lik in me. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4179 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class                                            message\n",
       "0      ham  ahhhh...just woken up!had a bad dream about u ...\n",
       "1      ham                           you can never do nothing\n",
       "2      ham  now u sound like manky scouse boy steve,like! ...\n",
       "3      ham  mum say we wan to go then go... then she can s...\n",
       "4      ham  never y lei... i v lazy... got wat? dat day ü ...\n",
       "...    ...                                                ...\n",
       "4174   ham  just woke up. yeesh its late. but i didn't fal...\n",
       "4175   ham  what do u reckon as need 2 arrange transport i...\n",
       "4176  spam  free entry into our £250 weekly competition ju...\n",
       "4177  spam  -pls stop bootydelious (32/f) is inviting you ...\n",
       "4178   ham  tell my  bad character which u dnt lik in me. ...\n",
       "\n",
       "[4179 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [\"class\", \"message\"]\n",
    "train_file = pd.read_csv(train_file_path, sep='\\t', names=names)\n",
    "train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>i am in hospital da. . i will return home in e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>not much, just some textin'. how bout you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>i probably won't eat at all today. i think i'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>don‘t give a flying monkeys wot they think and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>who are you seeing?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>ham</td>\n",
       "      <td>true dear..i sat to pray evening and felt so.s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>ham</td>\n",
       "      <td>what will we do in the shower, baby?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>ham</td>\n",
       "      <td>where are you ? what are you doing ? are yuou ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>spam</td>\n",
       "      <td>ur cash-balance is currently 500 pounds - to m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>spam</td>\n",
       "      <td>not heard from u4 a while. call 4 rude chat pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1392 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class                                            message\n",
       "0      ham  i am in hospital da. . i will return home in e...\n",
       "1      ham         not much, just some textin'. how bout you?\n",
       "2      ham  i probably won't eat at all today. i think i'm...\n",
       "3      ham  don‘t give a flying monkeys wot they think and...\n",
       "4      ham                                who are you seeing?\n",
       "...    ...                                                ...\n",
       "1387   ham  true dear..i sat to pray evening and felt so.s...\n",
       "1388   ham               what will we do in the shower, baby?\n",
       "1389   ham  where are you ? what are you doing ? are yuou ...\n",
       "1390  spam  ur cash-balance is currently 500 pounds - to m...\n",
       "1391  spam  not heard from u4 a while. call 4 rude chat pr...\n",
       "\n",
       "[1392 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file = pd.read_csv(test_file_path, sep='\\t', names=names)\n",
    "test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_message = train_file[\"message\"].values.tolist()\n",
    "train_label = np.array([0 if x==\"ham\" else 1 for x in train_file['class'].values.tolist()])\n",
    "test_message = test_file[\"message\"].values.tolist()\n",
    "test_label = np.array([0 if x==\"ham\" else 1 for x in test_file['class'].values.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_dict = {}\n",
    "for messgae in train_message:\n",
    "  for vocabulary in messgae.split():\n",
    "    if vocabulary not in vocabulary_dict:\n",
    "      vocabulary_dict[vocabulary] = 1\n",
    "    else:\n",
    "      vocabulary_dict[vocabulary] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocabulary_dict)\n",
    "MAX_LENGTH = len(max(train_message, key=lambda p: len(p.split())).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train_message = [one_hot(d, VOCAB_SIZE) for d in train_message]\n",
    "padded_train_message = pad_sequences(encoded_train_message, maxlen=MAX_LENGTH, padding='post')\n",
    "encoded_test_message = [one_hot(d, VOCAB_SIZE) for d in test_message]\n",
    "padded_test_message = pad_sequences(encoded_test_message, maxlen=MAX_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtual devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stonie/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "I0000 00:00:1730877048.769955   43098 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730877048.770289   43098 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730877048.770414   43098 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730877048.838706   43098 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730877048.838886   43098 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730877048.838997   43098 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-06 10:10:48.839100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2048 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-11-06 10:10:48.856315: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 2.00GiB (2147483648 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.856428: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 1.80GiB (1932735232 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.856495: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 1.62GiB (1739461632 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.856548: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 1.46GiB (1565515520 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.856686: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 1.31GiB (1408964096 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.856770: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 1.18GiB (1268067840 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.856844: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 1.06GiB (1141261056 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.856919: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 979.55MiB (1027134976 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.856990: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 881.60MiB (924421632 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.857060: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 793.44MiB (831979520 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.857131: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 714.09MiB (748781568 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.857200: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 642.68MiB (673903616 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.857271: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 578.42MiB (606513408 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.857339: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 520.57MiB (545862144 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.857408: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 468.52MiB (491276032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.857476: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 421.67MiB (442148608 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.857547: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 379.50MiB (397933824 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.857596: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 341.55MiB (358140672 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.857643: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 307.39MiB (322326784 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.857693: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 276.66MiB (290094336 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.857740: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 248.99MiB (261084928 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.857786: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 224.09MiB (234976512 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.857832: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 201.68MiB (211479040 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.857878: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 181.51MiB (190331136 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.857923: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 163.36MiB (171298048 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.857973: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 147.03MiB (154168320 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.858021: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 132.32MiB (138751488 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-11-06 10:10:48.858067: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 119.09MiB (124876544 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730877049.646898   43371 service.cc:146] XLA service 0x7afd640182a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1730877049.646967   43371 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Ti Laptop GPU, Compute Capability 8.6\n",
      "2024-11-06 10:10:49.684455: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-06 10:10:49.818461: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:536] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\n",
      "2024-11-06 10:10:49.818547: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:540] Memory usage: 4784128 bytes free, 4084400128 bytes total.\n",
      "2024-11-06 10:10:49.818599: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:550] Possibly insufficient driver version: 550.120.0\n",
      "2024-11-06 10:10:49.827625: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:536] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\n",
      "2024-11-06 10:10:49.827684: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:540] Memory usage: 4784128 bytes free, 4084400128 bytes total.\n",
      "2024-11-06 10:10:49.827722: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:550] Possibly insufficient driver version: 550.120.0\n",
      "2024-11-06 10:10:49.830559: W tensorflow/core/framework/op_kernel.cc:1840] OP_REQUIRES failed at xla_ops.cc:577 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2024-11-06 10:10:49.830608: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/stonie/miniconda3/lib/python3.12/asyncio/base_events.py\", line 639, in run_forever\n\n  File \"/home/stonie/miniconda3/lib/python3.12/asyncio/base_events.py\", line 1985, in _run_once\n\n  File \"/home/stonie/miniconda3/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_43098/1310276803.py\", line 8, in <module>\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_one_step_on_iterator_1094]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      7\u001b[0m monitor \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadded_train_message\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpadded_test_message\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_label\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/stonie/miniconda3/lib/python3.12/asyncio/base_events.py\", line 639, in run_forever\n\n  File \"/home/stonie/miniconda3/lib/python3.12/asyncio/base_events.py\", line 1985, in _run_once\n\n  File \"/home/stonie/miniconda3/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_43098/1310276803.py\", line 8, in <module>\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\n\n  File \"/home/stonie/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_one_step_on_iterator_1094]"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(VOCAB_SIZE, 100, input_length=MAX_LENGTH)\n",
    "model.add(embedding_layer)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "monitor = EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=25, verbose=1, mode='max', restore_best_weights=True)\n",
    "model.fit(padded_train_message, train_label, validation_data=(padded_test_message, test_label),epochs=500, verbose=2, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "[8.925416e-13, 'ham']\n"
     ]
    }
   ],
   "source": [
    "def predict_message(pred_text):\n",
    "  class_dict = {\n",
    "      0 : \"ham\", \n",
    "      1 : \"spam\",   \n",
    "      }\n",
    "  encoded_message = [one_hot(pred_text, VOCAB_SIZE)]\n",
    "  padded_message = pad_sequences(encoded_message, maxlen=MAX_LENGTH, padding='post')\n",
    "  prediction = [model.predict(padded_message)[0][0], class_dict[np.round(model.predict(padded_message)[0][0])]]\n",
    "  return prediction\n",
    "\n",
    "pred_text = \"how are you doing today?\"\n",
    "\n",
    "prediction = predict_message(pred_text)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "ham::ham\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "ham::spam\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "ham::ham\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "spam::spam\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "spam::spam\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "ham::ham\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "ham::ham\n",
      "You haven't passed yet. Keep trying.\n"
     ]
    }
   ],
   "source": [
    "def test_predictions():\n",
    "  test_messages = [\"how are you doing today\",\n",
    "                   \"sale today! to stop texts call 98912460324\",\n",
    "                   \"i dont want to go. can we try it a different day? available sat\",\n",
    "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
    "                   \"you have won £1000 cash! call to claim your prize.\",\n",
    "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
    "                   \"wow, is your arm alright. that happened to me one time too\"\n",
    "                  ]\n",
    "\n",
    "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
    "  passed = True\n",
    "\n",
    "  for msg, ans in zip(test_messages, test_answers):\n",
    "    prediction = predict_message(msg)\n",
    "    print(prediction[1] + '::' + ans)\n",
    "    if prediction[1] != ans:\n",
    "      passed = False\n",
    "\n",
    "  if passed:\n",
    "    print(\"You passed the challenge. Great job!\")\n",
    "  else:\n",
    "    print(\"You haven't passed yet. Keep trying.\")\n",
    "\n",
    "test_predictions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
